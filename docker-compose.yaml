version: '3'

services:
  # Auth Service and Database
  auth_db:
    image: postgres:16
    ports:
      - "5433:5432"
    volumes:
      - postgres_users_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=12345
      - POSTGRES_DB=auth_db
      - POSTGRES_PORT=5432

  auth_service:
    build: ./AuthService
    ports:
      - "8000:8000"
    depends_on:
      - auth_db
    environment:
      - FLASK_APP=app.py
      - FLASK_ENV=development
      - DATABASE_URL=postgresql://postgres:12345@auth_db/auth_db
    volumes:
      - ./AuthService:/app

  # Task Service and Database
  tasks_db:
    image: postgres:16
    ports:
      - "5434:5432"
    volumes:
      - postgres_tasks_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=12345
      - POSTGRES_DB=tasks_db
      - POSTGRES_PORT=5433

  task_service:
    build: ./TaskService
    ports:
      - "50051:50051"
    depends_on:
      - tasks_db
    environment:
      - DATABASE_URL=postgresql://postgres:12345@tasks_db/tasks_db
    volumes:
      - ./TaskService:/app
  
  kafka:
    container_name: "kafka"
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka
    restart: unless-stopped
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_JMX_PORT: 9997
    ports:
      - "9092:9092"
  kafka-ui:
    container_name: "kafka-ui"
    image: provectuslabs/kafka-ui
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: 'local'
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 'kafka:29092'
      KAFKA_CLUSTERS_0_METRICS_PORT: 9997
      DYNAMIC_CONFIG_ENABLED: 'true'
    ports:
      - "8081:8080"
  init-kafka:
    container_name: "init-kafka"
    image: confluentinc/cp-kafka:7.6.0
    depends_on:
      - kafka
    entrypoint: [ "/bin/sh", "-c" ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic task_tracker_views --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic task_tracker_likes --replication-factor 1 --partitions 1
      
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:29092 --list
      "

  clickhouse_stats:
    image: bitnami/clickhouse:latest
    environment:
      CLICKHOUSE_DB: default
      CLICKHOUSE_ADMIN_USER: clickhouse
      CLICKHOUSE_ADMIN_PASSWORD: clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - "clickhouse_stats:/bitnami/clickhouse"
      - "./StatisticsService/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql"
    depends_on:
      - init-kafka
    healthcheck:
      test: [ "CMD", "clickhouse-client", "--query", "SELECT 1" ]
      interval: 10s
      timeout: 5s
      retries: 5


volumes:
  postgres_users_data:
    external: true
  postgres_tasks_data:
    external: true
  clickhouse_stats:
    external: true
